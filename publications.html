<!--TEMPLATE TO ADD NEW PUBLICATIONS - replace caps  

   <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b>PAPER TITLE</b></papertitle>
        <br><em>AUTHORS</em><br>
        <a href="LINK" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="LINK" target="_blank"><paperlink>project page</paperlink></a>
    </div>

-->

<!DOCTYPE HTML>

<html lang="en">

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Intelligence through Decision Making and Interaction</title>
    <meta name="author" content="MIDI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="w3stylesheet.css">
    <link rel="stylesheet" href="midistyle.css"/>
    <link rel="shortcut icon" type=“image/x-icon” href="favicon.ico"/>
</head>

<body>
<!--Header section-->
    <!--background photo--> <header class="w3-container" style="text-align:center; background-image: url('homepageimages/CoverGradient.png');
        background-size: cover; width:100%; max-height: 20vw">
        <img src="homepageimages/midilabanimated.png" style="max-width: 20vw; max-height: auto; padding-top:3.5vw">
        <h1 style="font-weight: bold; color:white"; margin: 1.5%">Publications</h1>
        <p style="text-align: center; color: white; margin: 1.5%; padding-bottom: 4vw"><em>Machine Intelligence through Decision-making and Interaction</em></p>
    </header>
 
<!--navigation bar -->
  <div class="topnav">     
    <topnav style="list-style: none; font-weight:bold; justify-content: space-around; display: flex ">
     <center>
     <a href="index.html">Home</a>
     <a href="people.html">People</a>
     <a class="active" href="publications.html">Publications</a>
     <a href="getting_involved.html" >Getting Involved</a>
     </center>
    </topnav>
 </div>



<!--2023 publications -->

<div class="w3-container"> 
    <h2 style="max-width: 100%; color: #70a9ff; font-weight:bold; margin: 5%; margin-bottom: 2.5%">2024</h2>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>AMAGO-2: Breaking the Multi-Task Barrier in Meta-Reinforcement Learning with Transformers</u></b></papertitle>
        <br><em>Jake Grigsby, Justin Sasek, <b>Samyak Parajuli</b>, <b>Daniel Adebi</b>, <b>Amy Zhang</b>, Yuke Zhu</em><br>
        <a href="https://arxiv.org/pdf/2406.17688" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://github.com/philippe-eecs/small-vision" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>EC-Diffuser: Multi-Object Manipulation via Entity-Centric Behavior Generation</u></b></papertitle>
        <br><em><b>Carl Qi</b>, Dan Haramati, Tal Daniel, Aviv Tamar, <b>Amy Zhang</b></em><br>
        <a href="https://arxiv.org/pdf/2406.17688" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://github.com/philippe-eecs/small-vision" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Unified Auto-Encoding with Masked Diffusion</u></b></papertitle>
        <br><em><b>Philippe Hansen-Estruch</b>, Sriram Vishwanath, <b>Amy Zhang</b>, Manan Tomar</em><br>
        <a href="https://arxiv.org/pdf/2406.17688" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://github.com/philippe-eecs/small-vision" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>SkiLD: Unsupervised Skill Discovery Guided by Factor Interactions</u></b></papertitle>
        <br><em>Zizhao Wang, Jiaheng Hu, <b>Caleb Chuck</b>, Stephen Chen, Roberto Martín-Martín, <b>Amy Zhang</b>, Scott Niekum, Peter Stone</em><br>
        <a href="https://arxiv.org/pdf/2410.18416" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://wangzizhao.github.io/SkiLD/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Automated Discovery of Functional Actual Causes in Complex Environments</u></b></papertitle>
        <br><em><b>Caleb Chuck</b>, Sankaran Vaidyanathan, Stephen Giguere, <b>Amy Zhang</b>, David Jensen, Scott Niekum</em><br>
        <a href="https://arxiv.org/pdf/2404.10883" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://calcharles.github.io/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Automated Discovery of Functional Actual Causes in Complex Environments</u></b></papertitle>
        <br><em><b>Caleb Chuck</b>, Sankaran Vaidyanathan, Stephen Giguere, <b>Amy Zhang</b>, David Jensen, Scott Niekum</em><br>
        <a href="https://arxiv.org/pdf/2404.10883" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://calcharles.github.io/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Learning Action-based Representations Using Invariance</u></b></papertitle>
        <br><em><b>Max Rudolph</b>, <b>Caleb Chuck</b>, Kevin Black, Misha Lvovsky, Scott Niekum, <b>Amy Zhang</b></em><br>
        <a href="https://arxiv.org/pdf/2403.16369" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://maxrudolph1.github.io/action-bisimulation-site/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <!-- 2023 -->

    <h2 style="max-width: 100%; color: #70a9ff; font-weight:bold; margin: 5%; margin-bottom: 2.5%">2023</h2>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>A Dual Approach to Imitation Learning from Observations with Offline Datasets</u></b></papertitle>
        <br><em><b>Harshit Sikchi</b>, <b>Caleb Chuck</b>, <b>Amy Zhang</b>, Scott Niekum</em><br>
        <a href="https://arxiv.org/pdf/2406.08805" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://hari-sikchi.github.io/dilo/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Robot Air Hockey: A Manipulation Testbed for Robot Learning with Reinforcement Learning</u></b></papertitle>
        <br><em>Caleb Chuck, Carl Qi, Michael J Munje, Shuozhe Li, Max Rudolph, Chang Shi, Siddhant Agarwal, Harshit Sikchi, Abhinav Peri, Sarthak Dayal, Evan Kuo, Kavan Mehta, Anthony Wang, Peter Stone, Amy Zhang, Scott Niekum</em><br>
        <a href="https://arxiv.org/pdf/2405.03113" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://rlairhockey.github.io/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Score Models for Offline Goal-Conditioned Reinforcement Learning</u></b></papertitle>
        <br><em><b>Harshit Sikchi</b>, Rohan Chitnis, Ahmed Touati, Alborz Geramifard, <b>Amy Zhang</b>, Scott Niekum</em><br>
        <a href="https://arxiv.org/pdf/2311.02013" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://hari-sikchi.github.io/smore/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Dual RL: Unification and new methods for reinforcement and imitation learning</u></b></papertitle>
        <br><em><b>Harshit Sikchi</b>, Qinqing Zheng, <b>Amy Zhang</b>, Scott Niekum</em><br>
        <a href="https://arxiv.org/pdf/2302.08560" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://hari-sikchi.github.io/dual-rl/" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>f-Policy Gradients: A General Framework for Goal Conditioned RL using f-Divergences</u></b></papertitle>
        <br><em><b>Siddhant Agarwal</b>, Ishan Durugkar, Peter Stone, <b>Amy Zhang</b></em><br>
        <a href="https://arxiv.org/abs/2310.06794v1" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://agarwalsiddhant10.github.io/projects/fpg.html" target="_blank"><paperlink>project page</paperlink></a>
    </div>

    <div class="w3-container" style="padding:0%; margin: 5%; margin-top: 2.5%"> 
        <papertitle><b><u>Imitation from Arbitrary Experience: A Dual Unification of Reinforcement and Imitation Learning Methods</u></b></papertitle>
        <br><em><b>Harshit Sikchi</b>, <b>Amy Zhang</b>, Scott Neikum</em><br>
        <a href="https://arxiv.org/abs/2302.08560" target="_blank"><paperlink>arxiv</paperlink></a> /
        <a href="https://arxiv.org/abs/2302.08560" target="_blank"><paperlink>project page</paperlink></a>
    </div>

<!--paste new publications above this line using template-->

</div>

<!--Footer--> 
<div class="footer">
    <footer>Copyright 2023 | MIDILab | The University of Texas at Austin</footer>
</div>

</body>

</html>
